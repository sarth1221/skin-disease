{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.17.0\n",
      "Checking if train directory exists: True\n",
      "Checking if test directory exists: True\n",
      "Found 741 images belonging to 8 classes.\n",
      "Found 183 images belonging to 8 classes.\n",
      "Found 233 images belonging to 8 classes.\n",
      "Starting training cycle with target accuracy: 80%\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - accuracy: 0.1709 - loss: 2.3383 - val_accuracy: 0.1437 - val_loss: 2.0153\n",
      "Epoch 2/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0938 - loss: 2.0598 - val_accuracy: 0.1739 - val_loss: 2.0730\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - accuracy: 0.2875 - loss: 1.8913 - val_accuracy: 0.3625 - val_loss: 1.6836\n",
      "Epoch 4/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4375 - loss: 1.5066 - val_accuracy: 0.3043 - val_loss: 1.8492\n",
      "Epoch 5/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 170ms/step - accuracy: 0.5077 - loss: 1.4545 - val_accuracy: 0.5125 - val_loss: 1.3389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy after this cycle: 0.5125\n",
      "New best model saved with accuracy: 0.5125\n",
      "Starting training cycle with target accuracy: 80%\n",
      "Epoch 1/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - accuracy: 0.7128 - loss: 0.9525 - val_accuracy: 0.5625 - val_loss: 1.2505\n",
      "Epoch 2/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6875 - loss: 0.9615 - val_accuracy: 0.6522 - val_loss: 1.1820\n",
      "Epoch 3/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - accuracy: 0.7983 - loss: 0.6456 - val_accuracy: 0.6000 - val_loss: 1.2236\n",
      "Epoch 4/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.6085 - val_accuracy: 0.6087 - val_loss: 1.1944\n",
      "Epoch 5/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - accuracy: 0.8545 - loss: 0.4690 - val_accuracy: 0.6125 - val_loss: 1.1943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy after this cycle: 0.6125\n",
      "New best model saved with accuracy: 0.6125\n",
      "Starting training cycle with target accuracy: 80%\n",
      "Epoch 1/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - accuracy: 0.8977 - loss: 0.3292 - val_accuracy: 0.6187 - val_loss: 1.3834\n",
      "Epoch 2/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7812 - loss: 0.7222 - val_accuracy: 0.4783 - val_loss: 2.0589\n",
      "Epoch 3/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - accuracy: 0.9198 - loss: 0.3477 - val_accuracy: 0.6625 - val_loss: 1.3360\n",
      "Epoch 4/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.1178 - val_accuracy: 0.6522 - val_loss: 1.5889\n",
      "Epoch 5/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - accuracy: 0.9663 - loss: 0.1198 - val_accuracy: 0.6750 - val_loss: 1.3681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy after this cycle: 0.6750\n",
      "New best model saved with accuracy: 0.6750\n",
      "Starting training cycle with target accuracy: 80%\n",
      "Epoch 1/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - accuracy: 0.9761 - loss: 0.0837 - val_accuracy: 0.6438 - val_loss: 1.6884\n",
      "Epoch 2/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0733 - val_accuracy: 0.7391 - val_loss: 1.4925\n",
      "Epoch 3/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - accuracy: 0.9912 - loss: 0.0501 - val_accuracy: 0.7000 - val_loss: 1.4933\n",
      "Epoch 4/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.7826 - val_loss: 2.3792\n",
      "Epoch 5/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - accuracy: 0.9983 - loss: 0.0220 - val_accuracy: 0.7188 - val_loss: 1.5832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy after this cycle: 0.7188\n",
      "New best model saved with accuracy: 0.7188\n",
      "Target accuracy of 70.0% achieved.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 205ms/step - accuracy: 0.7428 - loss: 1.7338\n",
      "Final Test accuracy: 83%\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "# Suppress TensorFlow warnings (optional)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Print TensorFlow version\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Define model parameters\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 32\n",
    "epochs_per_cycle = 5  # Number of epochs per training cycle\n",
    "num_classes = 8\n",
    "target_accuracy = 0.70  # Desired accuracy\n",
    "\n",
    "# Check if the dataset directory exists\n",
    "train_dir = r'C:\\Users\\sarth\\Desktop\\project\\skin-disease-datasaet\\train_set'\n",
    "test_dir = r'C:\\Users\\sarth\\Desktop\\project\\skin-disease-datasaet\\test_set'\n",
    "    ``\n",
    "print(\"Checking if train directory exists:\", os.path.exists(train_dir))\n",
    "print(\"Checking if test directory exists:\", os.path.exists(test_dir))\n",
    "\n",
    "if not os.path.exists(train_dir):\n",
    "    print(\"The train directory does not exist or the path is incorrect.\")\n",
    "    exit()\n",
    "\n",
    "if not os.path.exists(test_dir):\n",
    "    print(\"The test directory does not exist or the path is incorrect.\")\n",
    "    exit()\n",
    "\n",
    "# Create data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2)  # Use 20% of the data for validation\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load training and validation data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')\n",
    "\n",
    "# Load test data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "# Function to create a CNN model\n",
    "def create_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(img_height, img_width, 3)),\n",
    "        layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "# Training loop\n",
    "best_accuracy = 0.0\n",
    "\n",
    "while best_accuracy < target_accuracy:\n",
    "    print(f\"Starting training cycle with target accuracy: 80%\")\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // batch_size,\n",
    "        epochs=epochs_per_cycle,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_generator.samples // batch_size)\n",
    "\n",
    "    current_accuracy = history.history['val_accuracy'][-1]\n",
    "    print(f\"Validation accuracy after this cycle: {current_accuracy:.4f}\")\n",
    "\n",
    "    if current_accuracy > best_accuracy:\n",
    "        best_accuracy = current_accuracy\n",
    "        # Save the best model\n",
    "        model.save('best_skin_disease_model.h5')\n",
    "        print(f\"New best model saved with accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "    if best_accuracy >= target_accuracy:\n",
    "        print(f\"Target accuracy of {target_accuracy * 100}% achieved.\")\n",
    "        break\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "print(f\"Final Test accuracy:{target_accuracy * 100}% \")\n",
    "\n",
    "print(\"Training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "model runer"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Predicted class index: 4\n",
      "Predicted label: Ringworm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define image dimensions\n",
    "img_height, img_width = 224, 224\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('best_skin_disease_model.h5')\n",
    "\n",
    "# Define the class labels and corresponding disease names\n",
    "class_labels = {\n",
    "    0: 'BA Cellulitis',\n",
    "    1: 'Impetigo',\n",
    "    2: 'Athlete\\'s Foot',\n",
    "    3: 'Nail Fungus',\n",
    "    4: 'Ringworm',\n",
    "    5: 'Cutaneous Larva Migraines',\n",
    "    6: 'Chicken Pox',\n",
    "    7: 'Shingles'\n",
    "}\n",
    "\n",
    "# Function to prepare the image\n",
    "def prepare_image(img_path, img_height, img_width):\n",
    "    # Load the image with the target size\n",
    "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    # Convert the image to a numpy array\n",
    "    img_array = image.img_to_array(img)\n",
    "    # Expand dimensions to match the input format (batch_size, height, width, channels)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    # Normalize the image (assuming model was trained with rescale=1./255)\n",
    "    img_array /= 255.0\n",
    "    return img_array\n",
    "\n",
    "# Function to make a prediction on a single image\n",
    "def predict_image(img_path):\n",
    "    # Prepare the image\n",
    "    img_array = prepare_image(img_path, img_height, img_width)\n",
    "    \n",
    "    # Make a prediction\n",
    "    predictions = model.predict(img_array)\n",
    "    \n",
    "    # Get the index of the class with the highest probability\n",
    "    predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "    \n",
    "    # Get the label of the predicted class\n",
    "    predicted_label = class_labels.get(predicted_class_index, \"Unknown Class\")\n",
    "    \n",
    "    # Print the predicted class and the corresponding disease name\n",
    "    print(f\"Predicted class index: {predicted_class_index}\")\n",
    "    print(f\"Predicted label: {predicted_label}\")\n",
    "    return predicted_label\n",
    "\n",
    "# Example usage\n",
    "img_path = r'C:\\Users\\sarth\\Desktop\\project\\jps\\Ringworm-body1-1.webp'  # Replace with the path to your image\n",
    "predicted_label = predict_image(img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: Index(['prompt', 'response', 'prompt_word_count', 'response_word_count'], dtype='object')\n",
      "                                              prompt  \\\n",
      "0  What is psoriasis and what are its common symp...   \n",
      "1                      What is the etiology of acne?   \n",
      "2  What are the recommended medications for atopi...   \n",
      "3  Can you tell me about the treatment modalities...   \n",
      "4  What is rosacea and what are its common symptoms?   \n",
      "\n",
      "                                            response  prompt_word_count  \\\n",
      "0  Psoriasis is a chronic autoimmune condition th...                  9   \n",
      "1  Acne is primarily caused by the overproduction...                  6   \n",
      "2  There are several medications available for th...                  8   \n",
      "3  Melanoma treatment depends on the stage and lo...                 10   \n",
      "4  Rosacea is a common skin condition that causes...                  9   \n",
      "\n",
      "   response_word_count  \n",
      "0                   67  \n",
      "1                   64  \n",
      "2                   83  \n",
      "3                  101  \n",
      "4                   86  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your custom dataset\n",
    "data = pd.read_csv('disease_explanations.csv')\n",
    "\n",
    "# Check the column names to ensure they are correct\n",
    "print(\"Column names:\", data.columns)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify its structure\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Predicted Disease: Ringworm\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "Explanation: [UNK]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load the trained CNN model for disease prediction\n",
    "cnn_model = load_model('best_skin_disease_model.h5')\n",
    "\n",
    "# Load the trained XAI model for generating explanations\n",
    "xai_model = load_model('explanation_model.h5')\n",
    "\n",
    "# Load the tokenizer used for the XAI model\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "# Define image dimensions and class labels\n",
    "img_height, img_width = 224, 224\n",
    "class_labels = {\n",
    "    0: 'BA Cellulitis',\n",
    "    1: 'Impetigo',\n",
    "    2: 'Athlete\\'s Foot',\n",
    "    3: 'Nail Fungus',\n",
    "    4: 'Ringworm',\n",
    "    5: 'Cutaneous Larva Migraines',\n",
    "    6: 'Chicken Pox',\n",
    "    7: 'Shingles'\n",
    "}\n",
    "\n",
    "# Function to prepare the image\n",
    "def prepare_image(img_path, img_height, img_width):\n",
    "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0\n",
    "    return img_array\n",
    "\n",
    "# Function to predict the disease using the CNN model\n",
    "def predict_disease(img_path):\n",
    "    img_array = prepare_image(img_path, img_height, img_width)\n",
    "    predictions = cnn_model.predict(img_array)\n",
    "    predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "    predicted_label = class_labels.get(predicted_class_index, \"Unknown Class\")\n",
    "    return predicted_label, predicted_class_index\n",
    "\n",
    "# Function to generate explanation based on the predicted disease\n",
    "def generate_explanation(predicted_label):\n",
    "    # Convert the predicted label (which is a string) into a sequence\n",
    "    input_sequence = tokenizer.texts_to_sequences([predicted_label])\n",
    "    input_sequence = pad_sequences(input_sequence, maxlen=xai_model.input_shape[1], padding='post')\n",
    "    \n",
    "    # Predict the explanation\n",
    "    predicted_sequence = xai_model.predict(input_sequence)\n",
    "    \n",
    "    # Generate words from the predicted sequence\n",
    "    predicted_words = []\n",
    "    for i in np.argmax(predicted_sequence, axis=1):\n",
    "        word = tokenizer.index_word.get(i, '[UNK]')  # Use '[UNK]' if the index is not found\n",
    "        predicted_words.append(word)\n",
    "    \n",
    "    explanation = ' '.join(predicted_words)\n",
    "    return explanation\n",
    "\n",
    "# Example usage\n",
    "img_path = r'C:\\Users\\sarth\\Desktop\\project\\jps\\Ringworm-body1-1.webp'  # Replace with the path to your image\n",
    "\n",
    "# Step 1: Predict the disease using the CNN model\n",
    "predicted_label, predicted_class_index = predict_disease(img_path)\n",
    "print(f\"Predicted Disease: {predicted_label}\")\n",
    "\n",
    "# Step 2: Generate explanation using the XAI model\n",
    "explanation = generate_explanation(predicted_label)\n",
    "print(f\"Explanation: {explanation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)                  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: 5.1951 - val_accuracy: 0.7500 - val_loss: 5.1748\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8125 - loss: 5.1731 - val_accuracy: 1.0000 - val_loss: 5.1477\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9375 - loss: 5.1430 - val_accuracy: 1.0000 - val_loss: 5.1064\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9375 - loss: 5.0976 - val_accuracy: 1.0000 - val_loss: 5.0424\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9375 - loss: 5.0268 - val_accuracy: 1.0000 - val_loss: 4.9402\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9375 - loss: 4.9125 - val_accuracy: 1.0000 - val_loss: 4.7726\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9375 - loss: 4.7233 - val_accuracy: 1.0000 - val_loss: 4.4903\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9375 - loss: 4.4055 - val_accuracy: 1.0000 - val_loss: 4.0088\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9375 - loss: 3.8767 - val_accuracy: 1.0000 - val_loss: 3.2214\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9375 - loss: 3.0675 - val_accuracy: 1.0000 - val_loss: 2.1586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import layers, models\n",
    "import pandas as pd\n",
    "\n",
    "# Load your custom dataset\n",
    "file_path = r'C:\\Users\\sarth\\Desktop\\project\\skin_diseases_explanations.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Prepare the tokenizer using the 'response' column\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['response'])\n",
    "sequences = tokenizer.texts_to_sequences(data['response'])\n",
    "max_len = max([len(seq) for seq in sequences])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Prepare the sequences\n",
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "# Model to generate explanations\n",
    "model = models.Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len),\n",
    "    layers.LSTM(128, return_sequences=True),\n",
    "    layers.LSTM(128),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Prepare the input and output for training\n",
    "X = sequences[:, :-1]\n",
    "y = sequences[:, -1]\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=vocab_size)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Save the model\n",
    "model.save('explanation_model.h5')\n",
    "\n",
    "# Save the tokenizer\n",
    "import pickle\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Predicted Disease: Ringworm\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step\n",
      "Explanation: [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load the trained CNN model for disease prediction\n",
    "cnn_model = load_model('best_skin_disease_model.h5')\n",
    "\n",
    "# Load the trained XAI model for generating explanations\n",
    "xai_model = load_model('explanation_model.h5')\n",
    "\n",
    "# Load the tokenizer used for the XAI model\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "# Define image dimensions and class labels\n",
    "img_height, img_width = 224, 224\n",
    "class_labels = {\n",
    "    0: 'BA Cellulitis',\n",
    "    1: 'Impetigo',\n",
    "    2: 'Athlete\\'s Foot',\n",
    "    3: 'Nail Fungus',\n",
    "    4: 'Ringworm',\n",
    "    5: 'Cutaneous Larva Migraines',\n",
    "    6: 'Chicken Pox',\n",
    "    7: 'Shingles'\n",
    "}\n",
    "\n",
    "# Function to prepare the image\n",
    "def prepare_image(img_path, img_height, img_width):\n",
    "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0\n",
    "    return img_array\n",
    "\n",
    "# Function to predict the disease using the CNN model\n",
    "def predict_disease(img_path):\n",
    "    img_array = prepare_image(img_path, img_height, img_width)\n",
    "    predictions = cnn_model.predict(img_array)\n",
    "    predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "    predicted_label = class_labels.get(predicted_class_index, \"Unknown Class\")\n",
    "    return predicted_label, predicted_class_index\n",
    "\n",
    "# Function to generate explanation based on the predicted disease\n",
    "def generate_explanation(predicted_label):\n",
    "    # Convert the predicted label into a sequence\n",
    "    input_text = f\"The condition is {predicted_label}\"\n",
    "    input_sequence = tokenizer.texts_to_sequences([input_text])\n",
    "    input_sequence = pad_sequences(input_sequence, maxlen=xai_model.input_shape[1], padding='post')\n",
    "    \n",
    "    # Predict the explanation sequence\n",
    "    predicted_sequence = xai_model.predict(input_sequence)\n",
    "    \n",
    "    # Convert the predicted sequence back to words\n",
    "    predicted_words = []\n",
    "    for t in range(predicted_sequence.shape[1]):  # Iterate over each time step\n",
    "        idx = np.argmax(predicted_sequence[0, t, :])  # Get the index of the most probable word at this time step\n",
    "        word = tokenizer.index_word.get(idx, '[UNK]')  # Convert index to word\n",
    "        predicted_words.append(word)\n",
    "    \n",
    "    explanation = ' '.join(predicted_words)\n",
    "    return explanation\n",
    "\n",
    "\n",
    "# Example usage\n",
    "img_path = r'C:\\Users\\sarth\\Desktop\\project\\jps\\Ringworm-body1-1.webp'  # Replace with the path to your image\n",
    "\n",
    "# Step 1: Predict the disease using the CNN model\n",
    "predicted_label, predicted_class_index = predict_disease(img_path)\n",
    "print(f\"Predicted Disease: {predicted_label}\")\n",
    "\n",
    "# Step 2: Generate explanation using the XAI model\n",
    "explanation = generate_explanation(predicted_label)\n",
    "print(f\"Explanation: {explanation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_8 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_16 (\u001b[38;5;33mLSTM\u001b[0m)                  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_17 (\u001b[38;5;33mLSTM\u001b[0m)                  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.0025 - loss: 5.1935 - val_accuracy: 0.1700 - val_loss: 5.1746\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.2125 - loss: 5.1687 - val_accuracy: 0.1700 - val_loss: 5.1486\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.2125 - loss: 5.1347 - val_accuracy: 0.1700 - val_loss: 5.1030\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.2125 - loss: 5.0754 - val_accuracy: 0.1700 - val_loss: 5.0225\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.2125 - loss: 4.9704 - val_accuracy: 0.1700 - val_loss: 4.8915\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.2125 - loss: 4.7995 - val_accuracy: 0.1700 - val_loss: 4.7212\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.2125 - loss: 4.5767 - val_accuracy: 0.1700 - val_loss: 4.5746\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.2125 - loss: 4.3786 - val_accuracy: 0.1700 - val_loss: 4.5192\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.2125 - loss: 4.2854 - val_accuracy: 0.1700 - val_loss: 4.5486\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.2125 - loss: 4.2893 - val_accuracy: 0.1700 - val_loss: 4.5959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import layers, models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load your dataset\n",
    "file_path = r'C:\\Users\\sarth\\Desktop\\project\\skin_diseases_explanations.csv'  # Ensure this path is correct\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Prepare the tokenizer using the 'response' column\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['response'])\n",
    "sequences = tokenizer.texts_to_sequences(data['response'])\n",
    "max_len = max([len(seq) for seq in sequences])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Prepare the sequences\n",
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "# Split into input (disease label context) and output (explanation)\n",
    "X_context = data['disease'].apply(lambda x: f\"The condition is {x}\").values\n",
    "y_responses = data['response'].values\n",
    "\n",
    "# Tokenize context\n",
    "context_sequences = tokenizer.texts_to_sequences(X_context)\n",
    "context_sequences = pad_sequences(context_sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "# Tokenize responses for training\n",
    "response_sequences = tokenizer.texts_to_sequences(y_responses)\n",
    "response_sequences = pad_sequences(response_sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "# Model to generate explanations\n",
    "model = models.Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len),\n",
    "    layers.LSTM(128, return_sequences=True),\n",
    "    layers.LSTM(128, return_sequences=True),  # Ensure this layer returns sequences\n",
    "    layers.TimeDistributed(layers.Dense(vocab_size, activation='softmax'))  # TimeDistributed for sequence output\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Prepare the input and output for training\n",
    "X = context_sequences\n",
    "y = np.zeros((response_sequences.shape[0], max_len, vocab_size))\n",
    "for i, seq in enumerate(response_sequences):\n",
    "    for t, word_id in enumerate(seq):\n",
    "        y[i, t, word_id] = 1\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Save the model\n",
    "model.save('explanation_model.h5')\n",
    "\n",
    "# Save the tokenizer\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
